{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvggish\n",
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "from panns_inference import AudioTagging\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: C:\\Users\\krzyzehj/panns_data/Cnn14_mAP=0.431.pth\n",
      "Using CPU.\n"
     ]
    }
   ],
   "source": [
    "# Initialize VGGish model and AudioSet classifier\n",
    "vggish_model = torchvggish.vggish()\n",
    "vggish_model.eval()\n",
    "audio_tagging = AudioTagging(checkpoint_path=None)  # Use the default pretrained checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract VGGish embeddings\n",
    "def extract_vggish_embeddings(wav_path):\n",
    "    try:\n",
    "        # Load and resample audio to 16kHz\n",
    "        y, sr = librosa.load(wav_path, sr=16000)\n",
    "        \n",
    "        # Generate Mel spectrogram\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(\n",
    "            y=y, sr=sr, n_mels=64, fmax=8000\n",
    "        )\n",
    "        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "        # Ensure Mel spectrogram shape is (64, 96) as expected by VGGish\n",
    "        if mel_spectrogram_db.shape != (64, 96):\n",
    "            from scipy.ndimage import zoom\n",
    "            mel_spectrogram_db = zoom(mel_spectrogram_db, (64 / mel_spectrogram_db.shape[0], 96 / mel_spectrogram_db.shape[1]))\n",
    "\n",
    "        # Convert to PyTorch tensor and add batch and channel dimensions\n",
    "        mel_spectrogram_db = torch.tensor(mel_spectrogram_db, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # Extract VGGish embeddings\n",
    "        with torch.no_grad():\n",
    "            embeddings = vggish_model(mel_spectrogram_db)\n",
    "        \n",
    "        return embeddings.squeeze().numpy()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify instruments using raw audio input\n",
    "def classify_instruments(wav_path):\n",
    "    try:\n",
    "        # Load and resample the audio file to 32kHz (required by the model)\n",
    "        y, sr = librosa.load(wav_path, sr=32000)\n",
    "        audio_tensor = torch.tensor(y).float().unsqueeze(0)  # Shape: [1, audio_length]\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            result = audio_tagging.inference(audio_tensor)\n",
    "\n",
    "        # Get the predicted tags\n",
    "        clipwise_output = np.array(result[0]).flatten()\n",
    "        instrument_predictions = []\n",
    "\n",
    "        target_labels = [\n",
    "            # Plucked string instruments\n",
    "            \"Guitar\", \"Electric guitar\", \"Bass guitar\", \"Acoustic guitar\", \n",
    "            \"Steel guitar, slide guitar\", \"Banjo\", \"Sitar\", \"Mandolin\", \n",
    "            \"Zither\", \"Ukulele\",\n",
    "            \n",
    "            # Keyboard instruments\n",
    "            \"Piano\", \"Electric piano\", \"Organ\", \"Electronic organ\", \n",
    "            \"Hammond organ\", \"Synthesizer\", \"Harpsichord\",\n",
    "            \n",
    "            # Percussion instruments\n",
    "            \"Drum kit\", \"Drum machine\", \"Snare drum\", \"Rimshot\", \n",
    "            \"Drum roll\", \"Bass drum\", \"Timpani\", \"Tabla\", \n",
    "            \"Cymbal\", \"Hi-hat\", \"Wood block\", \"Tambourine\", \n",
    "            \"Rattle (instrument)\", \"Maraca\", \"Gong\", \"Tubular bells\", \n",
    "            \"Marimba, xylophone\", \"Glockenspiel\", \"Vibraphone\", \"Steelpan\",\n",
    "            \n",
    "            # Orchestral instruments\n",
    "            \"Violin, fiddle\", \"Cello\", \"Double bass\", \"String section\", \n",
    "            \"Trumpet\", \"Trombone\", \"French horn\", \"Flute\", \n",
    "            \"Clarinet\", \"Saxophone\",\n",
    "            \n",
    "            # Miscellaneous instruments\n",
    "            \"Accordion\", \"Harmonica\", \"Harp\", \"Bagpipes\",\n",
    "            \n",
    "            # Effects or sounds\n",
    "            \"Singing\", \"Male singing\", \"Female singing\", \"Child singing\", \n",
    "            \"Choir\", \"Beatboxing\", \"Clapping\", \"Applause\"\n",
    "        ]\n",
    "\n",
    "        # Extract instrument labels based on high confidence predictions\n",
    "        for i, confidence in enumerate(clipwise_output):\n",
    "            # print(f\"Instrument: {audio_tagging.labels[i]} - Confidence rating: {confidence}\")\n",
    "            if confidence > 0.1:  # Use a threshold of 0.05 for prediction\n",
    "                label = audio_tagging.labels[i]\n",
    "                if label in target_labels:\n",
    "                    instrument_predictions.append(label)\n",
    "\n",
    "        return instrument_predictions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split up .wav file into five second increments and send these to the classifier\n",
    "def split_wav(wav_path):\n",
    "    output_folder = r\"Data/wav/wav_split/\"\n",
    "    chunk_length_ms = 1000\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    audio = AudioSegment.from_wav(wav_path)\n",
    "\n",
    "    total_length = len(audio)\n",
    "    num_chunks = total_length // chunk_length_ms\n",
    "\n",
    "    instrument_list = []\n",
    "    for i in range(num_chunks + 1):\n",
    "        start_time = i * chunk_length_ms\n",
    "        end_time = start_time + chunk_length_ms\n",
    "\n",
    "        chunk = audio[start_time:end_time]\n",
    "\n",
    "        if len(chunk) == 0 or chunk.dBFS < -60:\n",
    "            # print(f\"Skipping chunk {i + 1} due to silence or zero length.\")\n",
    "            continue\n",
    "\n",
    "        chunk_filename = os.path.join(output_folder, f\"chunk_{i + 1}.wav\")\n",
    "        chunk.export(chunk_filename, format=\"wav\")\n",
    "        \n",
    "        chunk_instruments = classify_instruments(chunk_filename)\n",
    "\n",
    "        # print(f\"Chunk {i + 1} instruments: {chunk_instruments}\")\n",
    "\n",
    "        for instrument in chunk_instruments:\n",
    "            if instrument not in instrument_list:\n",
    "                instrument_list.append(instrument)\n",
    "\n",
    "        # chunk_filename = os.path.join(output_folder, f\"chunk_{i + 1}.wav\")\n",
    "        # chunk.export(chunk_filename, format=\"wav\")\n",
    "    \n",
    "    # print(\"Splitting complete\")\n",
    "\n",
    "    return instrument_list\n",
    "\n",
    "print(vggish_model.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruments in file Data/wav/genres_original/classical/008RKiNmjW5Lb6Ocumq6MA.wav are... \n",
      " ['String section', 'Violin, fiddle', 'Cello', 'Piano', 'Double bass', 'Guitar']\n",
      "Instruments in file Data/wav/genres_original/classical/04eShjKTWijeJJqGnhxpYK.wav are... \n",
      " ['Violin, fiddle', 'Cello', 'String section', 'Clarinet']\n",
      "Instruments in file Data/wav/genres_original/classical/05rNWKxli5goHcA4e77sGC.wav are... \n",
      " ['Piano', 'Electric piano', 'Guitar']\n",
      "Instruments in file Data/wav/genres_original/classical/06am46cX3Z6YlSsg0TyVHA.wav are... \n",
      " ['Violin, fiddle', 'String section', 'Cello', 'Accordion', 'Guitar']\n",
      "Instruments in file Data/wav/genres_original/classical/07xafomqQcYmFJbr4jpfHa.wav are... \n",
      " ['Violin, fiddle', 'Cello', 'String section', 'Double bass']\n",
      "Instruments in file Data/wav/genres_original/classical/086sjLPEqdKBgTxbTeCLCv.wav are... \n",
      " ['Piano', 'Electric piano', 'Guitar', 'Acoustic guitar', 'Marimba, xylophone', 'Vibraphone']\n",
      "Instruments in file Data/wav/genres_original/classical/0Gef573AJfARbMuQSoCy2r.wav are... \n",
      " ['Piano', 'Marimba, xylophone', 'Glockenspiel', 'Vibraphone', 'Tubular bells', 'Harp', 'Electric piano', 'Cello', 'Double bass']\n",
      "Instruments in file Data/wav/genres_original/classical/0Gh45IbIKOG9IucFfrZqLT.wav are... \n",
      " ['String section', 'Violin, fiddle', 'Cello', 'Guitar', 'Double bass']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m wav_files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(TEST_PATH)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m wav_files:\n\u001b[1;32m----> 5\u001b[0m     instruments \u001b[38;5;241m=\u001b[39m \u001b[43msplit_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEST_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstruments in file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTEST_PATH\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are... \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstruments\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[45], line 27\u001b[0m, in \u001b[0;36msplit_wav\u001b[1;34m(wav_path)\u001b[0m\n\u001b[0;32m     24\u001b[0m chunk_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m chunk\u001b[38;5;241m.\u001b[39mexport(chunk_filename, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m chunk_instruments \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_instruments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# print(f\"Chunk {i + 1} instruments: {chunk_instruments}\")\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instrument \u001b[38;5;129;01min\u001b[39;00m chunk_instruments:\n",
      "Cell \u001b[1;32mIn[44], line 10\u001b[0m, in \u001b[0;36mclassify_instruments\u001b[1;34m(wav_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Perform inference\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maudio_tagging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Get the predicted tags\u001b[39;00m\n\u001b[0;32m     13\u001b[0m clipwise_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\panns_inference\\inference.py:71\u001b[0m, in \u001b[0;36mAudioTagging.inference\u001b[1;34m(self, audio)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 71\u001b[0m     output_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m clipwise_output \u001b[38;5;241m=\u001b[39m output_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclipwise_output\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     74\u001b[0m embedding \u001b[38;5;241m=\u001b[39m output_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\panns_inference\\models.py:133\u001b[0m, in \u001b[0;36mCnn14.forward\u001b[1;34m(self, input, mixup_lambda)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, mixup_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Input: (batch_size, data_length)\"\"\"\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspectrogram_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# (batch_size, 1, time_steps, freq_bins)\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogmel_extractor(x)    \u001b[38;5;66;03m# (batch_size, 1, time_steps, mel_bins)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchlibrosa\\stft.py:658\u001b[0m, in \u001b[0;36mSpectrogram.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    650\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate spectrogram of input signals.\u001b[39;00m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;124;03m    Args: \u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;124;03m        input: (batch_size, data_length)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;124;03m        spectrogram: (batch_size, 1, time_steps, n_fft // 2 + 1)\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 658\u001b[0m     (real, imag) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;66;03m# (batch_size, n_fft // 2 + 1, time_steps)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     spectrogram \u001b[38;5;241m=\u001b[39m real \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m imag \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchlibrosa\\stft.py:237\u001b[0m, in \u001b[0;36mSTFT.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter:\n\u001b[0;32m    235\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(x, pad\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_fft \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_fft \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mode)\n\u001b[1;32m--> 237\u001b[0m real \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m imag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_imag(x)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# (batch_size, n_fft // 2 + 1, time_steps)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[0;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "TEST_PATH = r\"Data/wav/genres_original/classical/\"\n",
    "wav_files = os.listdir(TEST_PATH)\n",
    "for file in wav_files:\n",
    "    instruments = split_wav(TEST_PATH + file)\n",
    "    print(f\"Instruments in file {TEST_PATH + file} are... \\n {instruments}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
