{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvggish\n",
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "from panns_inference import AudioTagging\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: C:\\Users\\krzyzehj/panns_data/Cnn14_mAP=0.431.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krzyzehj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\panns_inference\\inference.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU.\n"
     ]
    }
   ],
   "source": [
    "# Initialize VGGish model and AudioSet classifier\n",
    "vggish_model = torchvggish.vggish()\n",
    "vggish_model.eval()\n",
    "audio_tagging = AudioTagging(checkpoint_path=None)  # Use the default pretrained checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract VGGish embeddings\n",
    "def extract_vggish_embeddings(wav_path):\n",
    "    try:\n",
    "        # Load and resample audio to 16kHz\n",
    "        y, sr = librosa.load(wav_path, sr=16000)\n",
    "        \n",
    "        # Generate Mel spectrogram\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(\n",
    "            y=y, sr=sr, n_mels=64, fmax=8000\n",
    "        )\n",
    "        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "        # Ensure Mel spectrogram shape is (64, 96) as expected by VGGish\n",
    "        if mel_spectrogram_db.shape != (64, 96):\n",
    "            from scipy.ndimage import zoom\n",
    "            mel_spectrogram_db = zoom(mel_spectrogram_db, (64 / mel_spectrogram_db.shape[0], 96 / mel_spectrogram_db.shape[1]))\n",
    "\n",
    "        # Convert to PyTorch tensor and add batch and channel dimensions\n",
    "        mel_spectrogram_db = torch.tensor(mel_spectrogram_db, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # Extract VGGish embeddings\n",
    "        with torch.no_grad():\n",
    "            embeddings = vggish_model(mel_spectrogram_db)\n",
    "        \n",
    "        return embeddings.squeeze().numpy()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify instruments using raw audio input\n",
    "def classify_instruments(wav_path):\n",
    "    try:\n",
    "        # Load and resample the audio file to 32kHz (required by the model)\n",
    "        y, sr = librosa.load(wav_path, sr=32000)\n",
    "        audio_tensor = torch.tensor(y).float().unsqueeze(0)  # Shape: [1, audio_length]\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            result = audio_tagging.inference(audio_tensor)\n",
    "\n",
    "        # Get the predicted tags\n",
    "        clipwise_output = np.array(result[0]).flatten()\n",
    "        instrument_predictions = []\n",
    "\n",
    "        # Extract instrument labels based on high confidence predictions\n",
    "        for i, confidence in enumerate(clipwise_output):\n",
    "            # print(f\"Instrument: {audio_tagging.labels[i]} - Confidence rating: {confidence}\")\n",
    "            if confidence > 0.1:  # Use a threshold of 0.05 for prediction\n",
    "                label = audio_tagging.labels[i]\n",
    "                if label in [\n",
    "                    \"Guitar\", \"Bass guitar\", \"Violin\", \"Cello\", \"Flute\",\n",
    "                    \"Clarinet\", \"Saxophone\", \"Trumpet\", \"Piano\", \"Drum\",\n",
    "                    \"Cymbal\", \"Organ\"\n",
    "                ]:\n",
    "                    instrument_predictions.append(label)\n",
    "\n",
    "        return instrument_predictions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split up .wav file into five second increments and send these to the classifier\n",
    "def split_wav(wav_path):\n",
    "    output_folder = r\"Data/wav/wav_split/\"\n",
    "    chunk_length_ms = 2000\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    audio = AudioSegment.from_wav(wav_path)\n",
    "\n",
    "    total_length = len(audio)\n",
    "    num_chunks = total_length // chunk_length_ms\n",
    "\n",
    "    instrument_list = []\n",
    "    for i in range(num_chunks + 1):\n",
    "        start_time = i * chunk_length_ms\n",
    "        end_time = start_time + chunk_length_ms\n",
    "\n",
    "        chunk = audio[start_time:end_time]\n",
    "\n",
    "        if len(chunk) == 0 or chunk.dBFS < -60:\n",
    "            # print(f\"Skipping chunk {i + 1} due to silence or zero length.\")\n",
    "            continue\n",
    "\n",
    "        chunk_filename = os.path.join(output_folder, f\"chunk_{i + 1}.wav\")\n",
    "        chunk.export(chunk_filename, format=\"wav\")\n",
    "        \n",
    "        chunk_instruments = classify_instruments(chunk_filename)\n",
    "\n",
    "        # print(f\"Chunk {i + 1} instruments: {chunk_instruments}\")\n",
    "\n",
    "        for instrument in chunk_instruments:\n",
    "            if instrument not in instrument_list:\n",
    "                instrument_list.append(instrument)\n",
    "\n",
    "        # chunk_filename = os.path.join(output_folder, f\"chunk_{i + 1}.wav\")\n",
    "        # chunk.export(chunk_filename, format=\"wav\")\n",
    "    \n",
    "    # print(\"Splitting complete\")\n",
    "\n",
    "    return instrument_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruments in file Data/wav/genres_original/classical/008RKiNmjW5Lb6Ocumq6MA.wav are... \n",
      " ['Cello', 'Piano']\n",
      "Instruments in file Data/wav/genres_original/classical/04eShjKTWijeJJqGnhxpYK.wav are... \n",
      " ['Cello']\n",
      "Instruments in file Data/wav/genres_original/classical/05rNWKxli5goHcA4e77sGC.wav are... \n",
      " ['Piano']\n",
      "Instruments in file Data/wav/genres_original/classical/06am46cX3Z6YlSsg0TyVHA.wav are... \n",
      " ['Cello']\n",
      "Instruments in file Data/wav/genres_original/classical/07xafomqQcYmFJbr4jpfHa.wav are... \n",
      " ['Cello']\n",
      "Instruments in file Data/wav/genres_original/classical/086sjLPEqdKBgTxbTeCLCv.wav are... \n",
      " ['Piano', 'Guitar']\n",
      "Instruments in file Data/wav/genres_original/classical/0Gef573AJfARbMuQSoCy2r.wav are... \n",
      " ['Piano', 'Cello']\n",
      "Instruments in file Data/wav/genres_original/classical/0Gh45IbIKOG9IucFfrZqLT.wav are... \n",
      " ['Cello']\n",
      "Instruments in file Data/wav/genres_original/classical/0gsBQy8Q0eWlR67xDmoWFw.wav are... \n",
      " ['Piano']\n",
      "Instruments in file Data/wav/genres_original/classical/0iEIVX3DPGPX3ESUEXNsQv.wav are... \n",
      " ['Cello', 'Flute']\n",
      "Instruments in file Data/wav/genres_original/classical/0jOnZhF75V68VsBObWx2XO.wav are... \n",
      " ['Cello', 'Piano', 'Guitar']\n",
      "Instruments in file Data/wav/genres_original/classical/0k6P9cdEA9K3k0ASde2Kof.wav are... \n",
      " ['Guitar', 'Cello', 'Flute', 'Clarinet']\n",
      "Instruments in file Data/wav/genres_original/classical/0ltGW9V99yHuAk5U2kZYM6.wav are... \n",
      " ['Piano']\n",
      "Instruments in file Data/wav/genres_original/classical/0mcgXc8P5GyGtP9aY7zir6.wav are... \n",
      " ['Trumpet', 'Saxophone']\n",
      "Instruments in file Data/wav/genres_original/classical/0mTUTkFQ2MxmUHFL8EdfeR.wav are... \n",
      " []\n",
      "Instruments in file Data/wav/genres_original/classical/0nrCOJpS3gpwLvoANVZEeJ.wav are... \n",
      " ['Piano', 'Guitar']\n",
      "Instruments in file Data/wav/genres_original/classical/0NxCQL5OFodinhM1GO5dxi.wav are... \n",
      " ['Cello', 'Piano']\n",
      "Instruments in file Data/wav/genres_original/classical/0oIQl9tFpCiKBRavEIIGzo.wav are... \n",
      " ['Cello', 'Flute']\n",
      "Instruments in file Data/wav/genres_original/classical/0oN921mKYPOVYhKceZofrs.wav are... \n",
      " ['Piano', 'Cello']\n",
      "Instruments in file Data/wav/genres_original/classical/0P7pARLkje1gh85CEGgJtk.wav are... \n",
      " ['Cello']\n",
      "Instruments in file Data/wav/genres_original/classical/0qFZYO72iBOhW7X6KbL44Q.wav are... \n",
      " []\n",
      "Instruments in file Data/wav/genres_original/classical/0QTaXZRWdzfPdssiQThdCL.wav are... \n",
      " ['Piano', 'Cello']\n",
      "Instruments in file Data/wav/genres_original/classical/0S0YKiEdR9cT9pYgEaTevF.wav are... \n",
      " []\n",
      "Instruments in file Data/wav/genres_original/classical/0sonJpr4X0IXBWa7n0XlES.wav are... \n",
      " ['Cello']\n",
      "Instruments in file Data/wav/genres_original/classical/0URENFI2Nk9oVMdhz4SQKM.wav are... \n",
      " []\n",
      "Instruments in file Data/wav/genres_original/classical/0vzSIBAqnN1HzvWrPbh6VF.wav are... \n",
      " ['Piano', 'Guitar', 'Bass guitar']\n",
      "Instruments in file Data/wav/genres_original/classical/0w4LgJ5G1Xz5jLS3HX8oyq.wav are... \n",
      " ['Cello']\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "TEST_PATH = r\"Data/wav/genres_original/classical/\"\n",
    "wav_files = os.listdir(TEST_PATH)\n",
    "for file in wav_files:\n",
    "    instruments = split_wav(TEST_PATH + file)\n",
    "    print(f\"Instruments in file {TEST_PATH + file} are... \\n {instruments}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
